{
  
    
        "post0": {
            "title": "Real Estate Prediction",
            "content": "import pandas as pd import numpy as np import seaborn as sns import matplotlib.pyplot as plt . real_estate_df = pd.read_csv(&#39;Real estate.csv&#39;) real_estate_df = real_estate_df.drop(&#39;No&#39;,axis=1) . real_estate_df = real_estate_df.rename(columns = {&quot;X1 transaction date&quot;:&quot;transaction_date&quot;, &quot;X2 house age&quot;: &quot;house_age&quot;, &quot;X3 distance to the nearest MRT station&quot;: &quot;distance_to_train_station&quot;, &quot;X4 number of convenience stores&quot;:&quot;num_stores&quot;, &quot;Y house price of unit area&quot;:&quot;price_perunit_area&quot;, &quot;X5 latitude&quot;:&quot;latitude&quot;, &quot;X6 longitude&quot;:&quot;longitude&quot;}) real_estate_df.transaction_date = real_estate_df.transaction_date.astype(int) real_estate_df . transaction_date house_age distance_to_train_station num_stores latitude longitude price_perunit_area . 0 2012 | 32.0 | 84.87882 | 10 | 24.98298 | 121.54024 | 37.9 | . 1 2012 | 19.5 | 306.59470 | 9 | 24.98034 | 121.53951 | 42.2 | . 2 2013 | 13.3 | 561.98450 | 5 | 24.98746 | 121.54391 | 47.3 | . 3 2013 | 13.3 | 561.98450 | 5 | 24.98746 | 121.54391 | 54.8 | . 4 2012 | 5.0 | 390.56840 | 5 | 24.97937 | 121.54245 | 43.1 | . ... ... | ... | ... | ... | ... | ... | ... | . 409 2013 | 13.7 | 4082.01500 | 0 | 24.94155 | 121.50381 | 15.4 | . 410 2012 | 5.6 | 90.45606 | 9 | 24.97433 | 121.54310 | 50.0 | . 411 2013 | 18.8 | 390.96960 | 7 | 24.97923 | 121.53986 | 40.6 | . 412 2013 | 8.1 | 104.81010 | 5 | 24.96674 | 121.54067 | 52.5 | . 413 2013 | 6.5 | 90.45606 | 9 | 24.97433 | 121.54310 | 63.9 | . 414 rows × 7 columns . real_estate_df.isnull().sum() . transaction_date 0 house_age 0 distance_to_train_station 0 num_stores 0 latitude 0 longitude 0 price_perunit_area 0 dtype: int64 . There is no Null Values in the Dataset Let&#39;s proceed to the correlation between the Data | . Correlation . In visualizing the correlation we can use the corr() function in dataframe and plot it along side with the heatmap for proper visualization | Lets check for field that are in strong correlation with the price which is our main predictor or dependent variable | . fig, ax = plt.subplots(figsize=(20,10 )) sns.heatmap(real_estate_df.corr(),cmap=&quot;YlGnBu&quot;, annot=True) plt.show() . ACcording to the above heatmap we can see clearly that there&#39;s a strong positive correlation between the price and the Locations (Latitude and Longitude) also the number of conveniencconvenience stores around | There is also a high negative correlation between the price and the Distance to the nearest train station i.e The farther the rain station the lower the price of the house and thetre is a slight negative correlation between the price and the house age | . sns.pairplot(real_estate_df) . &lt;seaborn.axisgrid.PairGrid at 0x1be905c89c8&gt; . Looking at the Above plot we should see the correlation simmilar to our heatmap . we can see the linear relationship on the scatter plots . | Now Lets plot the relationship between the distance to train station and the price on an individual plot . | . plt.scatter(real_estate_df.distance_to_train_station, real_estate_df.price_perunit_area) plt.show() . Single Linear Regression . Since the Distance to train station seems to have the highest correlation with price per unit area lets create a single linear regression with the variable | . Distance to Train station The Regressor(Predictor) . Price per unit area - The Dependent Variable . from sklearn.linear_model import LinearRegression from sklearn.model_selection import train_test_split . X = real_estate_df.distance_to_train_station # The regressor X = np.array(X).reshape(-1,1) y = real_estate_df.price_perunit_area # The dependent variable # Split data in to train and test X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42) . model = LinearRegression() model.fit(X_train,y_train) . LinearRegression() . Accuracy . Now that we&#39;ve split our data into train and test column and we&#39;ve build our LinearRegression Model | It&#39;s time to check how well our model is performing | . R Squared, Mean_absolute Error and mean_squared_error are the 3 main metrics for evaluating regression model . from sklearn import metrics ypred = model.predict(X_test) mean_absolute_error = metrics.mean_absolute_error(y_test,ypred) mean_squared_error = metrics.mean_squared_error(y_test,ypred) r2 = metrics.r2_score(y_test,ypred) print(&#39;mean_squared_error &#39;,mean_squared_error) print(&#39;R Squared error &#39;,r2*100,&#39;%&#39;) print(&#39;mean_absolute_error &#39;,mean_absolute_error) . mean_squared_error 91.67527988547297 R Squared error 42.84590230872936 % mean_absolute_error 7.366066990787932 . plt.scatter(x=ypred,y=y_test) plt.xlabel(&#39;Prediction Value&#39;) plt.ylabel(&#39;Actual Value&#39;) plt.show() . real_estate_df . transaction_date house_age distance_to_train_station num_stores latitude longitude price_perunit_area . 0 2012 | 32.0 | 84.87882 | 10 | 24.98298 | 121.54024 | 37.9 | . 1 2012 | 19.5 | 306.59470 | 9 | 24.98034 | 121.53951 | 42.2 | . 2 2013 | 13.3 | 561.98450 | 5 | 24.98746 | 121.54391 | 47.3 | . 3 2013 | 13.3 | 561.98450 | 5 | 24.98746 | 121.54391 | 54.8 | . 4 2012 | 5.0 | 390.56840 | 5 | 24.97937 | 121.54245 | 43.1 | . ... ... | ... | ... | ... | ... | ... | ... | . 409 2013 | 13.7 | 4082.01500 | 0 | 24.94155 | 121.50381 | 15.4 | . 410 2012 | 5.6 | 90.45606 | 9 | 24.97433 | 121.54310 | 50.0 | . 411 2013 | 18.8 | 390.96960 | 7 | 24.97923 | 121.53986 | 40.6 | . 412 2013 | 8.1 | 104.81010 | 5 | 24.96674 | 121.54067 | 52.5 | . 413 2013 | 6.5 | 90.45606 | 9 | 24.97433 | 121.54310 | 63.9 | . 414 rows × 7 columns . Mean Squared Error ( MSE ) is defined as Mean or Average of the square of the difference between actual and estimated values. This means that MSE is calculated by the square of the difference between the predicted and actual target variables, divided by the number of data points. It is always non–negative values and close to zero are better. . | Mean Absolute Error ( MAE ) is the sum of the absolute difference between actual and predicted values. Absolute difference means that if the result has a negative sign, it is ignored. . | The R² is calculated by dividing sum of squares of residuals from the regression model (SSres) by total sum of squares of errors from the average model (given by SStot ) and then subtract it from 1. . | . R-squared is always between 0 and 100%: 0% indicates that a low level of correlation, meaning a regression model that is not valid, but not in all cases. 100% indicates that two variables are perfectly correlated, i.e., with no variance at all. . Reference http://net-informations.com/ds/psa/ . Multiple LinearRegression . Creation of the Linear Regression model putting all other factor available in the dataset into consideration | . X2 = np.array(real_estate_df.iloc[:,0:6]) # Selecting all variables except our price y2 = np.array(real_estate_df.price_perunit_area).reshape(-1,1) X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.33, random_state=42) model2 = LinearRegression() model2.fit(X2_train,y2_train) . LinearRegression() . Accuracy 2 . Calculating accuracy for the multiple linear regression using the same metrics as above | . y2pred = model2.predict(X2_test) mean_absolute_error2 = metrics.mean_absolute_error(y2_test,y2pred) mean_squared_error2 = metrics.mean_squared_error(y2_test,y2pred) r22 = metrics.r2_score(y2_test,y2pred) print(&#39;mean_squared_error &#39;,mean_squared_error2) print(&#39;R Squared error &#39;,r22*100,&#39;%&#39;) print(&#39;mean_absolute_error &#39;,mean_absolute_error2) . mean_squared_error 70.04818318373745 R Squared error 56.32911391401425 % mean_absolute_error 5.960669161179014 . plt.scatter(x=y2pred,y=y2_test) plt.xlabel(&#39;Predictions for Multiple regression&#39;) plt.ylabel(&#39;Actual values for Multiple regression&#39;) plt.show() . Comparing Models . R Squared Single Linear Regression - 42 % Multiple Linear Regression - 56% | . Mean Squared Error Single Linear Regression - 90 Multiple Linear Regression - 71 note the closer to zero the better . | . Mean absolute error Single linear regression -- 7.3 Multiple linear regression - 5.6 The closer to zero the better . | . Therefore Predicting with multiple value is more accurate than predicting with just the distance to the train station since in real life there will be multiple factors contributing to the price of a house | . Conclusion . In this Notebook we&#39;ve visualize the Real Estate dataset downloaded from kaggle and we create two Linear regression Model The first one with a single regressor(Predictor) and the other one with multiple regressor and we&#39;ve also evaluate both model to see how they perform using 3 linear regression metrics i.e R2 , mean squared error and mean absolute error | . Thank You . Alonge Daniel Oluwasegun .",
            "url": "https://alonge9500.github.io/DATA-ANALYST-PORTFOLIOO/2022/06/27/RealEstatePredictor-LinearRegression.html",
            "relUrl": "/2022/06/27/RealEstatePredictor-LinearRegression.html",
            "date": " • Jun 27, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Data Analyst Portfolio Project",
            "content": "[BONUS] WEB Scrapping (BeautifulSoup) . Scrapping The first page of the search result from programming job search on indeed website . import requests from bs4 import BeautifulSoup # Getting Requests URL = &#39;https://ng.indeed.com/Software-Developer-jobs?vjk=72949a771a0f0ddc&#39; page = requests.get(URL) soup = BeautifulSoup(page.content, &quot;html.parser&quot;) . results = soup.find(id=&quot;mosaic-zone-jobcards&quot;) job_elements = results.find_all(&quot;div&quot;, class_=&quot;slider_container css-11g4k3a eu4oa1w0&quot;) . title_list = [] company_list =[] location_list = [] description_list = [] for job in job_elements: title = job.find(&quot;h2&quot;, class_=&quot;jobTitle&quot;).text company = job.find(&quot;span&quot;, class_=&quot;companyName&quot;).text location = job.find(&quot;div&quot;, class_=&quot;companyLocation&quot;).text description = job.find(&quot;div&quot;, class_=&quot;job-snippet&quot;).text title_list.append(title) company_list.append(company) location_list.append(location) description_list.append(description) . import pandas as pd job_df = pd.DataFrame(list(zip(title_list,company_list,location_list,description_list)), index = range(len(title_list)), columns=[&#39;Title&#39;,&#39;Company Name&#39;,&#39;Location&#39;,&#39;Job Description&#39;]) . PERFORMING EDA ON HOTEL BOOKING DATA . The data hotel booking data was download from kaggle (https://www.kaggle.com/datasets/jessemostipak/hotel-booking-demand?resource=download) | Data description -&gt; This data set contains a single file which compares various booking information between two hotels: a city hotel and a resort hotel. | The dataset contains 32 columns which include arrival date, time spent, hotel names and other tangible information about the hotel | . Objectives . EDA(Exploratory Data Analysis) | Visualization | Hypothesis testing | Summary and Report | . import pandas as pd import numpy as np import seaborn as sns import matplotlib.pyplot as plt . hotel_booking= pd.read_csv(&#39;hotel_bookings.csv&#39;) . print(hotel_booking.shape) . (119390, 32) . The Dataset consist of 119390 rows and 32 Columns | . print(hotel_booking.info()) . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 119390 entries, 0 to 119389 Data columns (total 32 columns): # Column Non-Null Count Dtype -- -- 0 hotel 119390 non-null object 1 is_canceled 119390 non-null int64 2 lead_time 119390 non-null int64 3 arrival_date_year 119390 non-null int64 4 arrival_date_month 119390 non-null object 5 arrival_date_week_number 119390 non-null int64 6 arrival_date_day_of_month 119390 non-null int64 7 stays_in_weekend_nights 119390 non-null int64 8 stays_in_week_nights 119390 non-null int64 9 adults 119390 non-null int64 10 children 119386 non-null float64 11 babies 119390 non-null int64 12 meal 119390 non-null object 13 country 118902 non-null object 14 market_segment 119390 non-null object 15 distribution_channel 119390 non-null object 16 is_repeated_guest 119390 non-null int64 17 previous_cancellations 119390 non-null int64 18 previous_bookings_not_canceled 119390 non-null int64 19 reserved_room_type 119390 non-null object 20 assigned_room_type 119390 non-null object 21 booking_changes 119390 non-null int64 22 deposit_type 119390 non-null object 23 agent 103050 non-null float64 24 company 6797 non-null float64 25 days_in_waiting_list 119390 non-null int64 26 customer_type 119390 non-null object 27 adr 119390 non-null float64 28 required_car_parking_spaces 119390 non-null int64 29 total_of_special_requests 119390 non-null int64 30 reservation_status 119390 non-null object 31 reservation_status_date 119390 non-null object dtypes: float64(4), int64(16), object(12) memory usage: 29.1+ MB None . hotel_booking.describe() . is_canceled lead_time arrival_date_year arrival_date_week_number arrival_date_day_of_month stays_in_weekend_nights stays_in_week_nights adults children babies is_repeated_guest previous_cancellations previous_bookings_not_canceled booking_changes agent company days_in_waiting_list adr required_car_parking_spaces total_of_special_requests . count 119390.000000 | 119390.000000 | 119390.000000 | 119390.000000 | 119390.000000 | 119390.000000 | 119390.000000 | 119390.000000 | 119386.000000 | 119390.000000 | 119390.000000 | 119390.000000 | 119390.000000 | 119390.000000 | 103050.000000 | 6797.000000 | 119390.000000 | 119390.000000 | 119390.000000 | 119390.000000 | . mean 0.370416 | 104.011416 | 2016.156554 | 27.165173 | 15.798241 | 0.927599 | 2.500302 | 1.856403 | 0.103890 | 0.007949 | 0.031912 | 0.087118 | 0.137097 | 0.221124 | 86.693382 | 189.266735 | 2.321149 | 101.831122 | 0.062518 | 0.571363 | . std 0.482918 | 106.863097 | 0.707476 | 13.605138 | 8.780829 | 0.998613 | 1.908286 | 0.579261 | 0.398561 | 0.097436 | 0.175767 | 0.844336 | 1.497437 | 0.652306 | 110.774548 | 131.655015 | 17.594721 | 50.535790 | 0.245291 | 0.792798 | . min 0.000000 | 0.000000 | 2015.000000 | 1.000000 | 1.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 1.000000 | 6.000000 | 0.000000 | -6.380000 | 0.000000 | 0.000000 | . 25% 0.000000 | 18.000000 | 2016.000000 | 16.000000 | 8.000000 | 0.000000 | 1.000000 | 2.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 9.000000 | 62.000000 | 0.000000 | 69.290000 | 0.000000 | 0.000000 | . 50% 0.000000 | 69.000000 | 2016.000000 | 28.000000 | 16.000000 | 1.000000 | 2.000000 | 2.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 14.000000 | 179.000000 | 0.000000 | 94.575000 | 0.000000 | 0.000000 | . 75% 1.000000 | 160.000000 | 2017.000000 | 38.000000 | 23.000000 | 2.000000 | 3.000000 | 2.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 229.000000 | 270.000000 | 0.000000 | 126.000000 | 0.000000 | 1.000000 | . max 1.000000 | 737.000000 | 2017.000000 | 53.000000 | 31.000000 | 19.000000 | 50.000000 | 55.000000 | 10.000000 | 10.000000 | 1.000000 | 26.000000 | 72.000000 | 21.000000 | 535.000000 | 543.000000 | 391.000000 | 5400.000000 | 8.000000 | 5.000000 | . hotel_booking.head() hotel_booking.hotel.value_counts() . AttributeError Traceback (most recent call last) &lt;ipython-input-96-fec4be0f921b&gt; in &lt;module&gt; 1 hotel_booking.head() -&gt; 2 hotel_booking.hotel.value_counts() ~ Anaconda3 lib site-packages pandas core generic.py in __getattr__(self, name) 5272 if self._info_axis._can_hold_identifiers_and_holds_name(name): 5273 return self[name] -&gt; 5274 return object.__getattribute__(self, name) 5275 5276 def __setattr__(self, name: str, value) -&gt; None: AttributeError: &#39;Series&#39; object has no attribute &#39;hotel&#39; . agents = pd.isnull(hotel_booking.agent) (hotel_booking[agents]) . hotel is_canceled lead_time arrival_date_year arrival_date_month arrival_date_week_number arrival_date_day_of_month stays_in_weekend_nights stays_in_week_nights adults ... deposit_type agent company days_in_waiting_list customer_type adr required_car_parking_spaces total_of_special_requests reservation_status reservation_status_date . 0 Resort Hotel | 0 | 342 | 2015 | July | 27 | 1 | 0 | 0 | 2 | ... | No Deposit | NaN | NaN | 0 | Transient | 0.00 | 0 | 0 | Check-Out | 2015-07-01 | . 1 Resort Hotel | 0 | 737 | 2015 | July | 27 | 1 | 0 | 0 | 2 | ... | No Deposit | NaN | NaN | 0 | Transient | 0.00 | 0 | 0 | Check-Out | 2015-07-01 | . 2 Resort Hotel | 0 | 7 | 2015 | July | 27 | 1 | 0 | 1 | 1 | ... | No Deposit | NaN | NaN | 0 | Transient | 75.00 | 0 | 0 | Check-Out | 2015-07-02 | . 6 Resort Hotel | 0 | 0 | 2015 | July | 27 | 1 | 0 | 2 | 2 | ... | No Deposit | NaN | NaN | 0 | Transient | 107.00 | 0 | 0 | Check-Out | 2015-07-03 | . 18 Resort Hotel | 0 | 0 | 2015 | July | 27 | 1 | 0 | 1 | 2 | ... | No Deposit | NaN | 110.0 | 0 | Transient | 107.42 | 0 | 0 | Check-Out | 2015-07-02 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 119124 City Hotel | 0 | 0 | 2017 | August | 35 | 29 | 0 | 1 | 1 | ... | No Deposit | NaN | 72.0 | 0 | Transient | 0.00 | 0 | 2 | Check-Out | 2017-08-30 | . 119151 City Hotel | 0 | 0 | 2017 | August | 35 | 29 | 0 | 1 | 2 | ... | No Deposit | NaN | NaN | 0 | Transient | 270.00 | 0 | 0 | Check-Out | 2017-08-30 | . 119166 City Hotel | 0 | 0 | 2017 | August | 35 | 30 | 0 | 1 | 1 | ... | No Deposit | NaN | NaN | 0 | Transient | 140.00 | 0 | 0 | Check-Out | 2017-08-31 | . 119215 City Hotel | 0 | 2 | 2017 | August | 35 | 31 | 0 | 1 | 1 | ... | No Deposit | NaN | NaN | 0 | Transient | 140.00 | 0 | 2 | Check-Out | 2017-09-01 | . 119248 City Hotel | 0 | 22 | 2017 | August | 35 | 29 | 0 | 3 | 1 | ... | No Deposit | NaN | 485.0 | 0 | Transient | 75.00 | 0 | 4 | Check-Out | 2017-09-01 | . 16340 rows × 32 columns . hotel_booking.arrival_date_month.unique() month = { &#39;January&#39;:1, &#39;February&#39;:2, &#39;March&#39;:3, &#39;April&#39;:4, &#39;May&#39;:5, &#39;June&#39;:6, &#39;July&#39;:7, &#39;August&#39;:8, &#39;September&#39;:9, &#39;October&#39;:10, &#39;November&#39;:11, &#39;December&#39;:12 } hotel_booking.arrival_date_month = hotel_booking.arrival_date_month.replace(month) hotel_booking.head() . hotel is_canceled lead_time arrival_date_year arrival_date_month arrival_date_week_number arrival_date_day_of_month stays_in_weekend_nights stays_in_week_nights adults ... deposit_type agent company days_in_waiting_list customer_type adr required_car_parking_spaces total_of_special_requests reservation_status reservation_status_date . 0 Resort Hotel | 0 | 342 | 2015 | 7 | 27 | 1 | 0 | 0 | 2 | ... | No Deposit | NaN | NaN | 0 | Transient | 0.0 | 0 | 0 | Check-Out | 2015-07-01 | . 1 Resort Hotel | 0 | 737 | 2015 | 7 | 27 | 1 | 0 | 0 | 2 | ... | No Deposit | NaN | NaN | 0 | Transient | 0.0 | 0 | 0 | Check-Out | 2015-07-01 | . 2 Resort Hotel | 0 | 7 | 2015 | 7 | 27 | 1 | 0 | 1 | 1 | ... | No Deposit | NaN | NaN | 0 | Transient | 75.0 | 0 | 0 | Check-Out | 2015-07-02 | . 3 Resort Hotel | 0 | 13 | 2015 | 7 | 27 | 1 | 0 | 1 | 1 | ... | No Deposit | 304.0 | NaN | 0 | Transient | 75.0 | 0 | 0 | Check-Out | 2015-07-02 | . 4 Resort Hotel | 0 | 14 | 2015 | 7 | 27 | 1 | 0 | 2 | 2 | ... | No Deposit | 240.0 | NaN | 0 | Transient | 98.0 | 0 | 1 | Check-Out | 2015-07-03 | . 5 rows × 32 columns . hotel_booking.customer_type.value_counts() . Transient 89613 Transient-Party 25124 Contract 4076 Group 577 Name: customer_type, dtype: int64 . ax = sns.barplot(x=hotel_booking.arrival_date_month,y=range(len(hotel_booking)),hue= hotel_booking.hotel,estimator=np.count_nonzero) ax.set_xticks(range(12)) ax.set_xticklabels(month) plt.xticks(rotation=&#39;vertical&#39;) plt.xlabel(&#39;Arrival Month&#39;) plt.show() . plt.figure(figsize=(15,12)) sns.barplot(x=hotel_booking.arrival_date_week_number, y= range(len(hotel_booking)), estimator=np.count_nonzero) plt.show() . sns.barplot(x=hotel_booking.hotel,y=range(len(hotel_booking))) plt.show() . Visualization Report . dtypes: float64(4), int64(16), object(12) | From the dataset it was deduce that about 60%(79330) of the data fall in the city hotel while about 30%(40060) falls in the Resort Hotel | Despite that a larged amount of NULL value were present in the agent and company column we can still ignore them since they are of no significant importance to our analysis | With the low number of hotel visit in the month of December, Yet on the weekly scale there seems to be a high turnout in the hotel during the last week of the years ...... It could be assume that there are higher visits to the hotel during the Festive periods | And its really obvious that there are more vists to the Hotels during summer Holidays(June July August) | . Hypothesis . Are there possibilities that some hotels are preferable to the other depending on the particular time of the month ? . | NUll hypothesis : There&#39;s no relationship between the type of Hotel and the Month of visit . | Alternative Hypothesis : The Visit to the Hotel increases base on the month . | since its the correlation between two categorical variables we will Run Chi Square test using a pvalue of 0.05 . | . from scipy.stats import chi2_contingency # First create a contingency table table = pd.crosstab(hotel_booking.hotel,hotel_booking.arrival_date_month) table . arrival_date_month 1 2 3 4 5 6 7 8 9 10 11 12 . hotel . City Hotel 3736 | 4965 | 6458 | 7480 | 8232 | 7894 | 8088 | 8983 | 7400 | 7605 | 4357 | 4132 | . Resort Hotel 2193 | 3103 | 3336 | 3609 | 3559 | 3045 | 4573 | 4894 | 3108 | 3555 | 2437 | 2648 | . plt.figure(figsize=(12,8)) sns.heatmap(table, annot=True, cmap=&quot;YlGnBu&quot;) plt.show() . c, pvalue, dof, expected = chi2_contingency(table) . 3.5175313992493783e-119 . Hypothesis Report . Given a Pvalue of 3.517531399249378e-121 which is lower than the significance threshold implies that the probability of the relationship betwen the type of hotel and the month being random is very low | Therefore the Null Hypothesis which stated that there&#39;s no significant relationship between the two variables can be rejected | .",
            "url": "https://alonge9500.github.io/DATA-ANALYST-PORTFOLIOO/2022/06/17/Data-Analyst-Portfolio.html",
            "relUrl": "/2022/06/17/Data-Analyst-Portfolio.html",
            "date": " • Jun 17, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://alonge9500.github.io/DATA-ANALYST-PORTFOLIOO/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://alonge9500.github.io/DATA-ANALYST-PORTFOLIOO/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://alonge9500.github.io/DATA-ANALYST-PORTFOLIOO/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}